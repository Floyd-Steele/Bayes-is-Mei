{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Mei is Bayes'</H1><H3>a lesson in how to use Bayes' theorem to update a hypothesis</H3><br><br><p>Bayes' theorem allows one to calculate the posterior (or conditional) probability of an event occuring given the occurrence of another event. It can be conceptualized as a formula telling you how the probability of an event <b>changes</b> given the added information another event provides. It is often used to update the probabability a hypothesis is true given evidence. The most common formulation of the theorem is displayed below.<br><H1>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;P(A|B) = P(B|A)*P(A)/P(B)</H1><br>To interpret this formula, you must understand that P(A) denotes the probability event A occurs and P(A|B) denotes the probability A occurs <b>given</b> the occurrence of event B. Let's solve a fun problem using our formula. The problem involves a room containing duplicate characters from the game Overwatch. See below for a picture of the room.</p><br><img src= \"Pics/OW_sample_space.png\"/><br><p>At first glace, you can tell that there are 3 unique Overwatch characters represented in this <b>sample space</b>: Mei, Winston, and Reaper. It is also quite obvious that the room has been overtaken by Meis! Let's imagine that you have just entered the room. What is the probability that the first character you meet is a Mei? Well, that's easy enough. There are 15 total characters in the room and there are 12 Meis, so 12/15 = 0.8. Let's do this for all of the characters in the room. These probabilities are the <b>prior probabilities</b> of meeting one of these characters.      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prior Probabilities\n",
    "M = 12/15\n",
    "W = 2/15\n",
    "R = 1/15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>These probabilities correspond with P(A) in the above formula. That is, they are the probabilities of running into one of these characters given no extra information. But what if we are given extra information? If we want to determine the probability of meeting a Mei we should look at traits more associated with Mei than other characters. If you are familiar with 2016 memes, you already know that Mei is generally <b>bae</b>.</p><p>You can waste your own time looking up the definition of bae if you aren't already familiar with the concept. Below we rewrite our formula using M to denote Mei and B to denote bae.<img src=\"Pics/bae.png\"></p><br><H1>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;P(M|B) = P(B|M)*P(M)/P(B)</H1><br>The formula reads that the probability of meeting a Mei given that they are bae is equal to the probability of a character being bae given that they are a Mei times the probability of meeting a Mei, all divided by the probability of meeting a bae character. We have already caluclated P(M), but how do we determine the values of P(B|M) and P(B)? Well, to determine P(B|M) we need to know what proportion of the Meis are bae. Let's go ahead and calculate this proportion for all of the characters, assuming that 9/12 Meis, 1/2 Winstons, and 0 Reapers are bae. This probability is often referred to as the <b>likelihood</b> of one event given another. </p>     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Likelihoods\n",
    "B_M = 9/12\n",
    "B_W = 1/2\n",
    "B_R = 0/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The only piece of the puzzle missing at this point is P(B). This is the probability of any character being bae. I'll show you how to do this in 2 different ways. The most intuitive way of doing this is by adding up all of the bae characters (10 total) and dividing this value by the total number of characters (15 total). This gives us a 2/3 probability of first meeting a bae character upon entering the room. If you would like to learn a more advanced way of calculating this value study the calculation made in the third code cell below. This calculation is often referred to as the <b>marginal probability</b>. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation of Marginal Probability\n",
    "B = (B_M*M) + (B_W*W) + (B_R*R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now let's code a simple \"Bayes\" function which calculates <b>posterior probabilities</b>.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bayes' theorem function \n",
    "def Bayes(name,Y_X,X,Y):\n",
    "    print(f\"{name}:\",round(Y_X*X/Y,2))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Using this function be can easily calculate the conditional probability of meeting a certain character given whether they are bae or not. This probability is calculated for each character below.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mei: 0.9\n",
      "Winston: 0.1\n",
      "Reaper: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Conditional \"Posterior\" Probabilities \n",
    "Bayes(\"Mei\",B_M,M,B)\n",
    "Bayes(\"Winston\",B_W,W,B)\n",
    "Bayes(\"Reaper\",B_R,R,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The conditional probability of meeting a Mei given bae is 90%, this is 10% greater than the prior probability of meeting one. Notice that the probabilities of meeting a Winston or Reaper drop once you realize the character is bae. This is because Mei is <b>generally</b> bae while the other two <b>generally</b> aren't (Reapers don't appear to ever be bae, although a sample size of 1 leaves much to be desired). Let's see what happens when we decrease the number of Meis to 3, all of them bae. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mei: 0.75\n",
      "Winston: 0.25\n",
      "Reaper: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Prior Probabilities\n",
    "M = 3/6\n",
    "W = 2/6\n",
    "R = 1/6\n",
    "\n",
    "#Likelihoods\n",
    "B_M = 3/3\n",
    "B_W = 1/2\n",
    "B_R = 0/1\n",
    "\n",
    "#Calculation of Marginal Probability\n",
    "B = (B_M*M) + (B_W*W) + (B_R*R)\n",
    "\n",
    "#Conditional \"Posterior\" Probabilities \n",
    "Bayes(\"Mei\",B_M,M,B)\n",
    "Bayes(\"Winston\",B_W,W,B)\n",
    "Bayes(\"Reaper\",B_R,R,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>For this case, the conditional probability increased by 25%. Now let's increase the number of Winstons by 3, with 4 of them bae.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mei: 0.43\n",
      "Winston: 0.57\n",
      "Reaper: 0.0\n"
     ]
    }
   ],
   "source": [
    "#Prior Probabilities\n",
    "M = 3/9\n",
    "W = 5/9\n",
    "R = 1/9\n",
    "\n",
    "#Likelihoods\n",
    "B_M = 3/3\n",
    "B_W = 4/5\n",
    "B_R = 0/1\n",
    "\n",
    "#Calculation of Marginal Probability\n",
    "B = (B_M*M) + (B_W*W) + (B_R*R)\n",
    "\n",
    "#Conditional \"Posterior\" Probabilities \n",
    "Bayes(\"Mei\",B_M,M,B)\n",
    "Bayes(\"Winston\",B_W,W,B)\n",
    "Bayes(\"Reaper\",B_R,R,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Notice that even though 100% of Meis are bae compared to 80% of Winstons, there is still a higher probability of running into a Winston given that they are bae. This is due to the higher ratio of Winstons to Meis, and this is the power of Bayesian statistics. In Bayesian statistics (the branch of statistics supported by Bayes theorem) the likelihood of an object having some property is scaled by the number of those same objects represented in the sample. That is why despite the fact that almost all comedians are allegedly funny, you have a greater chance of meeting a funny non-comedian than a funny comedian. If you are interested in learning more, here is a link to an article introducting Bayesian networks (<a href=\"https://towardsdatascience.com/introduction-to-bayesian-networks-81031eeed94e\" URL>Link</a>). For my data scientists out there, here is a great StatQuest video explaining an application of the Naive Bayes classifier (<a href=\"https://www.youtube.com/watch?v=O2L2Uv9pdDA\" URL>Link</a>).</p>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Thanks for reading!!!</H1><img src=\"Pics/cute.png\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
